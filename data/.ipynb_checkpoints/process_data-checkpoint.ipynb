{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocessing data \n",
    "Disaster response pipeline project\n",
    "Data science nanodegree, Udacity \n",
    "\n",
    "Script execution:\n",
    "python process_data.py, disaster_messages.csv, disaster_categories.csv, DisasterResponse.db\n",
    "\n",
    "Arguments:\n",
    "    a) Csv file containing messages data (disaster_messages.csv)\n",
    "    b) Csv file containing categories data (disaster_categories.csv)\n",
    "    c) Sqlite destination database (DisasterResponse.db)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules \n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    " \n",
    "#functions \n",
    "\n",
    "def load_data(messages_filepath, categories_filepath):\n",
    "    \"\"\"\n",
    "    Load data function\n",
    "    \n",
    "    Arguments:\n",
    "        messages_filepath -> path to the csv file with messages \n",
    "        categories_filepath -> path to the csv file with categories \n",
    "    Output:\n",
    "        df -> pandas dataframe\n",
    "    \"\"\"\n",
    "    # load messages dataset\n",
    "    messages = pd.read_csv('messages.csv')\n",
    "    \n",
    "    # load categories dataset\n",
    "    categories = pd.read_csv('categories.csv')\n",
    "   \n",
    "    # merge datasets\n",
    "    df =  messages.merge(categories, on= 'id', how = 'inner')\n",
    "    \n",
    "    return df \n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Clean data function\n",
    "    \n",
    "    Arguments:\n",
    "        df -> dirty data pandas dataframe\n",
    "    Outputs:\n",
    "        df -> clean data pandas dataframe\n",
    "    \"\"\"\n",
    "    # create a dataframe of the 36 individual category columns\n",
    "    categories = df.categories.str.split(pat=';', expand=True)\n",
    "\n",
    "    # select the first row of the categories dataframe\n",
    "    row = categories.iloc[0,:]\n",
    "    category_colnames = row.apply(lambda x:x[:-2])\n",
    "\n",
    "    # rename the columns of `categories`\n",
    "    categories.columns = category_colnames\n",
    "\n",
    "    #convert category values to just numbers 0 or 1.\n",
    "    for column in categories:\n",
    "        # set each value to be the last character of the string\n",
    "        categories[column] = categories[column].astype(str).str[-1:]\n",
    "\n",
    "        # convert column from string to numeric\n",
    "        categories[column] = categories[column].astype(np.int)\n",
    "\n",
    "    #replace `categories` column in `df` with new category columns.\n",
    "    # drop the original categories column from `df`\n",
    "    df.drop('categories',axis=1)\n",
    "\n",
    "    # concatenate the original dataframe with the new `categories` dataframe\n",
    "    df = pd.concat([df,categories], join='inner', axis=1)\n",
    "    \n",
    "    # drop duplicates\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    return df\n",
    "\n",
    "def save_data(df, database_filename):\n",
    "    \"\"\"\n",
    "    Save data function\n",
    "    \n",
    "    Arguments:\n",
    "        df -> clean data Pandas DataFrame\n",
    "        database_filename -> database file (.db) destination path\n",
    "    \"\"\"\n",
    "    engine = create_engine('sqlite:///'+ database_filename)\n",
    "    df.to_sql('DisasterResponse', engine, index=False)\n",
    "    \n",
    "    \n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main data processing function\n",
    "    \n",
    "    Implementation of the 3 main actions to create the ETL pipeline:\n",
    "        1) Load the csv datasets  \n",
    "        2) Clean and pre-processing the data\n",
    "        3) Load and save the data to Sqlite database\n",
    "    \"\"\"\n",
    "    #if the count of arguments is matching to 4, execute the ETL pipeline \n",
    "    #print(sys.argv)\n",
    "    if len(sys.argv) == 4:\n",
    "        \n",
    "        #extract the parameters\n",
    "        messages_filepath, categories_filepath, database_filepath = sys.argv[1:]\n",
    "\n",
    "        #print messagges\n",
    "        print('Loading data from...\\n  MESSAGES: {} ....\\n Loading data from...\\n  CATEGORIES: {}'\n",
    "              .format(messages_filepath, categories_filepath))\n",
    "        df = load_data(messages_filepath, categories_filepath)\n",
    "\n",
    "        print('Cleaning categories data...')\n",
    "        df = clean_data(df)\n",
    "        \n",
    "        print('Saving data to SQLite DB ...\\n  DATABASE: {}'.format(database_filepath))\n",
    "        save_data(df, database_filepath)\n",
    "        \n",
    "        print('Cleaned data has been saved to database!')\n",
    "        \n",
    "        #print an error messagge \n",
    "    else:\n",
    "        print(\"Please provide arguments correctly: \\n\\nDatasets as the first and second argument respectively, \\n\\\n",
    "as well as the filepath of the database to save the cleaned data to as the third argument. \\n\\n\\\n",
    "-> Python process_data.py, disaster_messages.csv, disaster_categories.csv, disaster_response_db.db \\n\\n\\\n",
    "Arguments description: \\n\\\n",
    "a) Path to the csv file containing messages (e.g. disaster_messages.csv)\\n\\\n",
    "b) Path to the csv file containing categories (e.g. disaster_categories.csv)\\n\\\n",
    "c) Path to Sqlite destination database (e.g. disaster_response_db.db)\")\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
